# Resumo das Aulas de Aprendizado de M√°quina

Este reposit√≥rio cont√©m um resumo detalhado das aulas do curso de aprendizado de m√°quina, organizado por tema e com f√≥rmulas matem√°ticas formatadas para renderiza√ß√£o no GitHub.

---

## üìñ Conte√∫do

# Resumos dos PDFs

## **[slides01.pdf](https://work.caltech.edu/slides/slides01.pdf)**
### Introdu√ß√£o ao Problema de Aprendizado
#### Exemplo Pr√°tico: Avalia√ß√£o de Filmes
- Objetivo: Usar aprendizado de m√°quina para prever como um espectador avaliar√° um filme.
  - Fatores avaliados: g√™nero, popularidade, atores (ex.: "Tom Cruise").
  - Solu√ß√£o: Combinar contribui√ß√µes de fatores relacionados ao filme e ao espectador.

#### Componentes do Aprendizado
1. **Entrada (\(x\))**: Dados conhecidos (ex.: idade, sal√°rio).
2. **Sa√≠da (\(y\))**: Decis√£o ou valor previsto (ex.: bom ou mau cliente).
3. **Fun√ß√£o Alvo (\(f\))**: Regra ideal, mas desconhecida.
4. **Conjunto de Hip√≥teses (\(H\))**: Poss√≠veis f√≥rmulas candidatas.
5. **Algoritmo de Aprendizado**: Escolhe uma hip√≥tese \( g \) que melhor aproxima \( f \).

#### Modelo Simples: Perceptron
- Usado para decis√µes lineares.
- Exemplo: Aprova√ß√£o de cr√©dito com base em dados do cliente.
  - F√≥rmula:

$$
h(x) = \text{sign}\left(\sum_{i=1}^{d} w_i x_i - \text{threshold}\right)
$$

---

## **[slides02.pdf](https://work.caltech.edu/slides/slides02.pdf)**
### √â Vi√°vel Aprender?
#### Probabilidade e Generaliza√ß√£o
- Sem generalizar, n√£o √© poss√≠vel prever al√©m dos dados observados.
- Exemplo: Experimento com urnas e Hoeffding's Inequality:
  - Em um experimento de sorteio de bolinhas, a fra√ß√£o observada (\(\nu\)) tende a aproximar a probabilidade real (\(\mu\)).
  - F√≥rmula:

$$
P[|\nu - \mu| > \epsilon] \leq 2e^{-2\epsilon^2N}
$$

#### Liga√ß√£o com Aprendizado
- No aprendizado, a "urna" representa um conjunto de hip√≥teses.
- O aprendizado generaliza se a hip√≥tese escolhida (\(h\)) funcionar bem tanto para os dados de treinamento (\(\text{Ein}\)) quanto para dados desconhecidos (\(\text{Eout}\)).

---

## **[slides03.pdf](https://work.caltech.edu/slides/slides03.pdf)**
### Modelos Lineares I
#### Representa√ß√£o de Entrada
- Dados brutos (\(x\)) podem ser transformados em caracter√≠sticas mais √∫teis (ex.: intensidade, simetria).
- Um modelo linear usa pesos (\(w\)) para combinar essas caracter√≠sticas.

#### Classifica√ß√£o Linear vs Regress√£o Linear
- **Classifica√ß√£o**: Toma decis√µes bin√°rias, como "sim" ou "n√£o".
- **Regress√£o**: Prev√™ valores cont√≠nuos, como "quanto aprovar de cr√©dito".

#### Medindo o Erro
- Regress√£o usa o erro quadr√°tico m√©dio:

$$
\text{Ein}(h) = \frac{1}{N} \sum_{n=1}^N (h(x_n) - y_n)^2
$$

---

## **[slides04.pdf](https://work.caltech.edu/slides/slides04.pdf)**
### Erro e Ru√≠do
#### Transforma√ß√µes N√£o-Lineares
- Usadas para tratar dados n√£o-linearmente separ√°veis.
- Exemplo: Aplicar uma fun√ß√£o \(\phi(x)\) para mapear os dados para um espa√ßo onde possam ser separados.

#### Medidas de Erro
- Escolher a medida de erro adequada depende do problema.
- Exemplos:
  - **Erro Quadr√°tico**: Para problemas cont√≠nuos.
  - **Erro Bin√°rio**: Para decis√µes "certo" ou "errado".

#### Impacto do Ru√≠do
- Em muitos problemas, a sa√≠da observada (\(y\)) √© uma combina√ß√£o da fun√ß√£o alvo (\(f\)) mais um termo de ru√≠do.

---

## **[slides05.pdf](https://work.caltech.edu/slides/slides05.pdf)**
### Treinamento vs Teste
#### Diferen√ßas
- **Treinamento**: Dados usados para ajustar o modelo.
- **Teste**: Dados usados para avaliar a generaliza√ß√£o.

#### No√ß√£o de "Break Point"
- Ponto onde o modelo n√£o consegue mais separar corretamente os dados, indicando sobreajuste.

#### Fun√ß√£o de Crescimento
- Mede o n√∫mero de divis√µes que um modelo pode fazer em \(N\) pontos:

$$
m_H(N) \leq 2^N
$$

---

## **[slides06.pdf](https://work.caltech.edu/slides/slides06.pdf)**
### Teoria da Generaliza√ß√£o
#### Prova de que \(m_H(N)\) √© Polinomial
- \(m_H(N)\) cresce de forma limitada com o aumento dos dados.
- F√≥rmula recursiva relaciona o n√∫mero m√°ximo de divis√µes com o tamanho do conjunto:

$$
m_H(N) \leq \sum_{i=0}^{k-1} \binom{N}{i}
$$

#### Implica√ß√µes
- Um crescimento controlado de \(m_H(N)\) indica boa generaliza√ß√£o.

---

## **[slides07.pdf](https://work.caltech.edu/slides/slides07.pdf)**
### Dimens√£o VC
#### Defini√ß√£o
- A dimens√£o VC (\(d_{VC}\)) √© o n√∫mero m√°ximo de pontos que podem ser separados completamente por um conjunto de hip√≥teses.

#### Aplica√ß√µes
- Um \(d_{VC}\) maior indica maior capacidade do modelo, mas pode levar a sobreajuste.

---

## **[slides08.pdf](https://work.caltech.edu/slides/slides08.pdf)**
### Trade-Off Bias-Vari√¢ncia
#### Conceitos
- **Bias**: Erro devido √† simplicidade do modelo.
- **Vari√¢ncia**: Erro devido √† sensibilidade aos dados.

#### Curvas de Aprendizado
- Mostram como o erro muda com o aumento do n√∫mero de dados (\(N\)).

---

## **[slides09.pdf](https://work.caltech.edu/slides/slides09.pdf)**
### Modelo Linear II
#### Transforma√ß√µes N√£o-Lineares
- Adicionar dimens√µes (ex.: \(x^2\)) para lidar com dados mais complexos.
- Exemplo: Transformar \(x\) em:

$$
z = (x_1, x_2, x_1x_2, x_1^2, x_2^2)
$$

#### Regress√£o Log√≠stica
- Modelo probabil√≠stico:

$$
h(x) = \frac{1}{1 + e^{-w^Tx}}
$$

---

## **[slides10.pdf](https://work.caltech.edu/slides/slides10.pdf)**
### Redes Neurais
#### Stochastic Gradient Descent (SGD)
- M√©todo iterativo para ajustar pesos.
- Escolhe exemplos aleat√≥rios para calcular gradientes, reduzindo custo computacional.

#### Modelo de Rede Neural
- Combina√ß√£o de perceptrons organizados em camadas.
- Exemplo: Usar m√∫ltiplas camadas para resolver problemas n√£o-linearmente separ√°veis.

#### Backpropagation
- Algoritmo para ajustar pesos em redes profundas de forma eficiente.

---

## **[slides11.pdf](https://work.caltech.edu/slides/slides11.pdf)**
### Overfitting
- **Defini√ß√£o**: Ajustar os dados al√©m do necess√°rio, capturando o ru√≠do em vez do padr√£o.
- **Impactos**:
  - \(\text{Ein} \downarrow, \text{Eout} \uparrow\): Perda de generaliza√ß√£o.
  - **Ru√≠do determin√≠stico**: Parte da fun√ß√£o alvo (\(f(x)\)) que o modelo n√£o consegue capturar.

#### F√≥rmula do ru√≠do determin√≠stico:
$$
\text{Ru√≠do determin√≠stico} = f(x) - h^*(x)
$$

- **Caso pr√°tico**: Ajuste de dados com diferentes ordens polinomiais:
  - Modelo de 10¬™ ordem captura ru√≠do.
  - Modelo de 2¬™ ordem generaliza melhor.

---

## **[slides12.pdf](https://work.caltech.edu/slides/slides12.pdf)**
### Regulariza√ß√£o
- **Motiva√ß√£o**: Evitar overfitting restringindo a complexidade do modelo.
- **Erro Augmentado**:

$$
E_{\text{aug}}(w) = E_{\text{in}}(w) + \frac{\lambda}{N} w^T w
$$

- **Solu√ß√£o regularizada**:

$$
w_{\text{reg}} = (Z^T Z + \lambda I)^{-1} Z^T y
$$

- **Weight Decay**: Penaliza pesos altos, reduzindo a sensibilidade do modelo.

---

## **[slides13.pdf](https://work.caltech.edu/slides/slides13.pdf)**
### Valida√ß√£o e Sele√ß√£o de Modelos
- **Conceito**: Dividir os dados em conjuntos de treino (\(D_{\text{train}}\)) e valida√ß√£o (\(D_{\text{val}}\)).
- **Erro de Valida√ß√£o**:

$$
E_{\text{val}}(h) = \frac{1}{K} \sum_{k=1}^K e(h(x_k), y_k)
$$

- **Valida√ß√£o Cruzada**:
  - Divide os dados em \(K\)-folds e alterna entre treino e valida√ß√£o.
  - Erro m√©dio:

$$
E_{\text{cv}} = \frac{1}{K} \sum_{n=1}^N e(h_{-n}(x_n), y_n)
$$

---

## **[slides14.pdf](https://work.caltech.edu/slides/slides14.pdf)**
### M√°quinas de Vetores de Suporte (SVM)
- **Maximiza√ß√£o da Margem**:

$$
\text{Dist√¢ncia} = \frac{1}{\|w\|}
$$

- **Problema de otimiza√ß√£o**:

$$
\min \frac{1}{2} w^T w \quad \text{sujeito a } y_n (w^T x_n + b) \geq 1, \, \forall n
$$

- **Transforma√ß√µes N√£o Lineares**:
  - Mapeiam os dados para um espa√ßo de caracter√≠sticas \(Z\), onde se tornam linearmente separ√°veis.

---

## **[slides15.pdf](https://work.caltech.edu/slides/slides15.pdf)**
### M√©todos de Kernel
- **Truque do Kernel**:
  - Substitui o produto interno no espa√ßo \(Z\) pelo kernel \(K(x, x')\).
- **Exemplo de Kernel Polinomial**:

$$
K(x, x') = (1 + x^T x')^Q
$$

- **SVM com Kernel**:

$$
g(x) = \text{sign} \left( \sum_{n=1}^N \alpha_n y_n K(x_n, x) + b \right)
$$

---

## **[slides16.pdf](https://work.caltech.edu/slides/slides16.pdf)**
### Fun√ß√µes de Base Radial (RBF)
- **Modelo b√°sico**:

$$
h(x) = \sum_{n=1}^N w_n \exp(-\gamma \|x - x_n\|^2)
$$

- **Aprendizado**:
  - Determinar os pesos \(w_n\) resolvendo:

$$
\Phi w = y, \quad \Phi_{ij} = \exp(-\gamma \|x_i - x_j\|^2)
$$

- **Redu√ß√£o de complexidade**:
  - Usar \(K \ll N\) centros (\(\mu_k\)) em vez de todos os pontos de dados.

---

## **[slides17.pdf](https://work.caltech.edu/slides/slides17.pdf)**
### Tr√™s Princ√≠pios de Aprendizado
1. **Navalha de Occam**: O modelo mais simples que explica os dados √© o mais plaus√≠vel.
2. **Vi√©s de Amostragem**:
   - Diferen√ßas entre distribui√ß√£o de treino (\(P_{\text{train}}(x)\)) e teste (\(P_{\text{test}}(x)\)).
3. **Data Snooping**:
   - O uso repetido dos mesmos dados pode introduzir vi√©s e comprometer a avalia√ß√£o.

---

## **[slides18.pdf](https://work.caltech.edu/slides/slides18.pdf)**
### Ep√≠logo: O Mapa do Aprendizado de M√°quina
- **T√©cnicas e Paradigmas**:
  - Supervisionado, n√£o supervisionado, aprendizado por refor√ßo.
  - M√©todos como redes neurais, SVM, RBF, entre outros.
- **Aprendizado Bayesiano**:
  - Integra informa√ß√µes de distribui√ß√µes a priori para melhorar o aprendizado.
- **M√©todos de Agrega√ß√£o**:
  - Combina v√°rios modelos (\(h_1, h_2, \ldots, h_T\)):

$$
\text{Regress√£o: } \bar{h}(x) = \frac{1}{T} \sum_{t=1}^T h_t(x)
$$

$$
\text{Classifica√ß√£o: } \bar{h}(x) = \text{majority vote}
$$


---







## ‚ú® Cr√©ditos
Resumos baseados nas aulas de Yaser Abu-Mostafa no curso de Aprendizado de M√°quina da Caltech. Dispon√≠vel em [Learning From Data](https://work.caltech.edu/telecourse.html).
