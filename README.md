# Resumo das Aulas de Aprendizado de M√°quina

Este reposit√≥rio cont√©m um resumo detalhado das aulas do curso de aprendizado de m√°quina, organizado por tema e com f√≥rmulas matem√°ticas formatadas para renderiza√ß√£o no GitHub.

---

## üìñ Conte√∫do

# Resumos dos PDFs

## **[slides01.pdf](https://work.caltech.edu/slides/slides01.pdf)**
### Introdu√ß√£o ao Problema de Aprendizado
#### Exemplo Pr√°tico: Avalia√ß√£o de Filmes
- Objetivo: Usar aprendizado de m√°quina para prever como um espectador avaliar√° um filme.
  - Fatores avaliados: g√™nero, popularidade, atores (ex.: "Tom Cruise").
  - Solu√ß√£o: Combinar contribui√ß√µes de fatores relacionados ao filme e ao espectador.

#### Componentes do Aprendizado
1. **Entrada (\(x\))**: Dados conhecidos (ex.: idade, sal√°rio).
2. **Sa√≠da (\(y\))**: Decis√£o ou valor previsto (ex.: bom ou mau cliente).
3. **Fun√ß√£o Alvo (\(f\))**: Regra ideal, mas desconhecida.
4. **Conjunto de Hip√≥teses (\(H\))**: Poss√≠veis f√≥rmulas candidatas.
5. **Algoritmo de Aprendizado**: Escolhe uma hip√≥tese \( g \) que melhor aproxima \( f \).

#### Modelo Simples: Perceptron
- Usado para decis√µes lineares.
- Exemplo: Aprova√ß√£o de cr√©dito com base em dados do cliente.
  - F√≥rmula:

$$
h(x) = \text{sign}\left(\sum_{i=1}^{d} w_i x_i - \text{threshold}\right)
$$

---

## **[slides02.pdf](https://work.caltech.edu/slides/slides02.pdf)**
### √â Vi√°vel Aprender?
#### Probabilidade e Generaliza√ß√£o
- Sem generalizar, n√£o √© poss√≠vel prever al√©m dos dados observados.
- Exemplo: Experimento com urnas e Hoeffding's Inequality:
  - Em um experimento de sorteio de bolinhas, a fra√ß√£o observada (\(\nu\)) tende a aproximar a probabilidade real (\(\mu\)).
  - F√≥rmula:

$$
P[|\nu - \mu| > \epsilon] \leq 2e^{-2\epsilon^2N}
$$

#### Liga√ß√£o com Aprendizado
- No aprendizado, a "urna" representa um conjunto de hip√≥teses.
- O aprendizado generaliza se a hip√≥tese escolhida (\(h\)) funcionar bem tanto para os dados de treinamento (\(\text{Ein}\)) quanto para dados desconhecidos (\(\text{Eout}\)).

---

## **[slides03.pdf](https://work.caltech.edu/slides/slides03.pdf)**
### Modelos Lineares I
#### Representa√ß√£o de Entrada
- Dados brutos (\(x\)) podem ser transformados em caracter√≠sticas mais √∫teis (ex.: intensidade, simetria).
- Um modelo linear usa pesos (\(w\)) para combinar essas caracter√≠sticas.

#### Classifica√ß√£o Linear vs Regress√£o Linear
- **Classifica√ß√£o**: Toma decis√µes bin√°rias, como "sim" ou "n√£o".
- **Regress√£o**: Prev√™ valores cont√≠nuos, como "quanto aprovar de cr√©dito".

#### Medindo o Erro
- Regress√£o usa o erro quadr√°tico m√©dio:

$$
\text{Ein}(h) = \frac{1}{N} \sum_{n=1}^N (h(x_n) - y_n)^2
$$

---

## **[slides04.pdf](https://work.caltech.edu/slides/slides04.pdf)**
### Erro e Ru√≠do
#### Transforma√ß√µes N√£o-Lineares
- Usadas para tratar dados n√£o-linearmente separ√°veis.
- Exemplo: Aplicar uma fun√ß√£o \(\phi(x)\) para mapear os dados para um espa√ßo onde possam ser separados.

#### Medidas de Erro
- Escolher a medida de erro adequada depende do problema.
- Exemplos:
  - **Erro Quadr√°tico**: Para problemas cont√≠nuos.
  - **Erro Bin√°rio**: Para decis√µes "certo" ou "errado".

#### Impacto do Ru√≠do
- Em muitos problemas, a sa√≠da observada (\(y\)) √© uma combina√ß√£o da fun√ß√£o alvo (\(f\)) mais um termo de ru√≠do.

---

## **[slides05.pdf](https://work.caltech.edu/slides/slides05.pdf)**
### Treinamento vs Teste
#### Diferen√ßas
- **Treinamento**: Dados usados para ajustar o modelo.
- **Teste**: Dados usados para avaliar a generaliza√ß√£o.

#### No√ß√£o de "Break Point"
- Ponto onde o modelo n√£o consegue mais separar corretamente os dados, indicando sobreajuste.

#### Fun√ß√£o de Crescimento
- Mede o n√∫mero de divis√µes que um modelo pode fazer em \(N\) pontos:

$$
m_H(N) \leq 2^N
$$

---

## **[slides06.pdf](https://work.caltech.edu/slides/slides06.pdf)**
### Teoria da Generaliza√ß√£o
#### Prova de que \(m_H(N)\) √© Polinomial
- \(m_H(N)\) cresce de forma limitada com o aumento dos dados.
- F√≥rmula recursiva relaciona o n√∫mero m√°ximo de divis√µes com o tamanho do conjunto:

$$
m_H(N) \leq \sum_{i=0}^{k-1} \binom{N}{i}
$$

#### Implica√ß√µes
- Um crescimento controlado de \(m_H(N)\) indica boa generaliza√ß√£o.

---

## **[slides07.pdf](https://work.caltech.edu/slides/slides07.pdf)**
### Dimens√£o VC
#### Defini√ß√£o
- A dimens√£o VC (\(d_{VC}\)) √© o n√∫mero m√°ximo de pontos que podem ser separados completamente por um conjunto de hip√≥teses.

#### Aplica√ß√µes
- Um \(d_{VC}\) maior indica maior capacidade do modelo, mas pode levar a sobreajuste.

---

## **[slides08.pdf](https://work.caltech.edu/slides/slides08.pdf)**
### Trade-Off Bias-Vari√¢ncia
#### Conceitos
- **Bias**: Erro devido √† simplicidade do modelo.
- **Vari√¢ncia**: Erro devido √† sensibilidade aos dados.

#### Curvas de Aprendizado
- Mostram como o erro muda com o aumento do n√∫mero de dados (\(N\)).

---

## **[slides09.pdf](https://work.caltech.edu/slides/slides09.pdf)**
### Modelo Linear II
#### Transforma√ß√µes N√£o-Lineares
- Adicionar dimens√µes (ex.: \(x^2\)) para lidar com dados mais complexos.
- Exemplo: Transformar \(x\) em:

$$
z = (x_1, x_2, x_1x_2, x_1^2, x_2^2)
$$

#### Regress√£o Log√≠stica
- Modelo probabil√≠stico:

$$
h(x) = \frac{1}{1 + e^{-w^Tx}}
$$

---

## **[slides10.pdf](https://work.caltech.edu/slides/slides10.pdf)**
### Redes Neurais
#### Stochastic Gradient Descent (SGD)
- M√©todo iterativo para ajustar pesos.
- Escolhe exemplos aleat√≥rios para calcular gradientes, reduzindo custo computacional.

#### Modelo de Rede Neural
- Combina√ß√£o de perceptrons organizados em camadas.
- Exemplo: Usar m√∫ltiplas camadas para resolver problemas n√£o-linearmente separ√°veis.

#### Backpropagation
- Algoritmo para ajustar pesos em redes profundas de forma eficiente.

---

## ‚ú® Cr√©ditos
Resumos baseados nas aulas de Yaser Abu-Mostafa no curso de Aprendizado de M√°quina da Caltech. Dispon√≠vel em [Learning From Data](https://work.caltech.edu/telecourse.html).
